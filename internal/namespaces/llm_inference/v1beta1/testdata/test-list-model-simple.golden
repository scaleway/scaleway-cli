ğŸ²ğŸ²ğŸ² EXIT CODE: 0 ğŸ²ğŸ²ğŸ²
ğŸŸ©ğŸŸ©ğŸŸ© STDOUTï¸ ğŸŸ©ğŸŸ©ğŸŸ©ï¸
ID                                    Name                                     Provider  Tags
a7db3243-9d6a-4149-9ffb-081e24886d00  mistral/mixtral-8x7b-instruct-v0.1:fp16  mistral   [instruct]
c55d11d3-f717-4ede-82ac-48a74b84cbf1  mistral/mixtral-8x7b-instruct-v0.1:int8  mistral   [instruct]
2cf5427e-1cfd-4e9b-94e9-509e6a6a38a8  meta/llama-2-70b-chat:fp16               meta      [chat]
efbca7c6-9b76-49b2-8789-f89cc6df7eb7  meta/llama-2-70b-chat:fp8                meta      [chat]
729c0386-ddde-4209-ba91-fad5ec47e2bb  wizardlm/wizardlm-70b-v1.0:fp8           wizardlm  [instruct]
3077ebd3-3a5a-47fc-91c2-da8cf6779c56  wizardlm/wizardlm-70b-v1.0:fp16          wizardlm  [instruct]
ğŸŸ©ğŸŸ©ğŸŸ© JSON STDOUT ğŸŸ©ğŸŸ©ğŸŸ©
[
  {
    "id": "a7db3243-9d6a-4149-9ffb-081e24886d00",
    "name": "mistral/mixtral-8x7b-instruct-v0.1:fp16",
    "project_id": "",
    "provider": "mistral",
    "tags": [
      "instruct"
    ],
    "description": "A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.",
    "has_eula": false,
    "created_at": "2024-03-15T00:00:00Z",
    "updated_at": "1970-01-01T00:00:00.0Z",
    "region": "fr-par",
    "is_public": true,
    "compatible_node_types": [
      "H100-2"
    ],
    "quantization_level": "fp16"
  },
  {
    "id": "c55d11d3-f717-4ede-82ac-48a74b84cbf1",
    "name": "mistral/mixtral-8x7b-instruct-v0.1:int8",
    "project_id": "",
    "provider": "mistral",
    "tags": [
      "instruct"
    ],
    "description": "A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI, licensed under Apache 2.0.",
    "has_eula": false,
    "created_at": "2024-03-15T00:00:00Z",
    "updated_at": "1970-01-01T00:00:00.0Z",
    "region": "fr-par",
    "is_public": true,
    "compatible_node_types": [
      "H100"
    ],
    "quantization_level": "int8"
  },
  {
    "id": "2cf5427e-1cfd-4e9b-94e9-509e6a6a38a8",
    "name": "meta/llama-2-70b-chat:fp16",
    "project_id": "",
    "provider": "meta",
    "tags": [
      "chat"
    ],
    "description": "70B-param model by Meta, a powerhouse for creative text generation and complex reasoning.",
    "has_eula": true,
    "created_at": "2024-03-15T10:00:00Z",
    "updated_at": "1970-01-01T00:00:00.0Z",
    "region": "fr-par",
    "is_public": true,
    "compatible_node_types": [
      "H100-2"
    ],
    "quantization_level": "fp16"
  },
  {
    "id": "efbca7c6-9b76-49b2-8789-f89cc6df7eb7",
    "name": "meta/llama-2-70b-chat:fp8",
    "project_id": "",
    "provider": "meta",
    "tags": [
      "chat"
    ],
    "description": "70B-param model by Meta, a powerhouse for creative text generation and complex reasoning.",
    "has_eula": true,
    "created_at": "2024-03-15T10:00:00Z",
    "updated_at": "1970-01-01T00:00:00.0Z",
    "region": "fr-par",
    "is_public": true,
    "compatible_node_types": [
      "H100"
    ],
    "quantization_level": "fp8"
  },
  {
    "id": "729c0386-ddde-4209-ba91-fad5ec47e2bb",
    "name": "wizardlm/wizardlm-70b-v1.0:fp8",
    "project_id": "",
    "provider": "wizardlm",
    "tags": [
      "instruct"
    ],
    "description": "Empowering Large Pre-Trained Language Models to Follow Complex Instructions",
    "has_eula": true,
    "created_at": "2024-03-15T12:00:00Z",
    "updated_at": null,
    "region": "fr-par",
    "is_public": true,
    "compatible_node_types": [
      "H100"
    ],
    "quantization_level": "fp8"
  },
  {
    "id": "3077ebd3-3a5a-47fc-91c2-da8cf6779c56",
    "name": "wizardlm/wizardlm-70b-v1.0:fp16",
    "project_id": "",
    "provider": "wizardlm",
    "tags": [
      "instruct"
    ],
    "description": "General use 70B-param model based on Llama 2.",
    "has_eula": true,
    "created_at": "2024-03-15T12:00:00Z",
    "updated_at": "1970-01-01T00:00:00.0Z",
    "region": "fr-par",
    "is_public": true,
    "compatible_node_types": [
      "H100-2"
    ],
    "quantization_level": "fp16"
  }
]
