---
version: 1
interactions:
- request:
    body: '{"models":[{"id":"6c68b256-ef4a-48d2-a794-9b63b5c6ba5d","name":"meta/llama-3-8b-instruct:bf16","project_id":"","tags":["instruct","chat"],"description":"Efficient
      8B-param model by Meta, fine-tuned for instruction and automation.","is_public":true,"created_at":"2024-03-14T00:00:00Z","updated_at":"2024-05-28T08:45:34.779337Z","has_eula":true,"provider":"meta","compatible_node_types":["L4"],"quantization_level":"bf16","region":"fr-par"},{"id":"c55d11d3-f717-4ede-82ac-48a74b84cbf1","name":"mistral/mixtral-8x7b-instruct-v0.1:int8","project_id":"","tags":["instruct"],"description":"A
      high-quality Mixture of Experts (MoE) model with open weights by Mistral AI,
      licensed under Apache 2.0.","is_public":true,"created_at":"2024-03-15T00:00:00Z","updated_at":"2024-05-28T08:45:34.749698Z","has_eula":false,"provider":"mistral","compatible_node_types":["H100"],"quantization_level":"int8","region":"fr-par"},{"id":"a7db3243-9d6a-4149-9ffb-081e24886d00","name":"mistral/mixtral-8x7b-instruct-v0.1:fp16","project_id":"","tags":["instruct"],"description":"A
      high-quality Mixture of Experts (MoE) model with open weights by Mistral AI,
      licensed under Apache 2.0.","is_public":true,"created_at":"2024-03-15T00:00:00Z","updated_at":"2024-05-28T08:45:34.736199Z","has_eula":false,"provider":"mistral","compatible_node_types":["H100-2"],"quantization_level":"fp16","region":"fr-par"},{"id":"2cf5427e-1cfd-4e9b-94e9-509e6a6a38a8","name":"meta/llama-2-70b-chat:fp16","project_id":"","tags":["chat"],"description":"70B-param
      model by Meta, a powerhouse for creative text generation and complex reasoning.","is_public":true,"created_at":"2024-03-15T10:00:00Z","updated_at":"2024-05-28T08:45:34.723363Z","has_eula":true,"provider":"meta","compatible_node_types":["H100-2"],"quantization_level":"fp16","region":"fr-par"},{"id":"efbca7c6-9b76-49b2-8789-f89cc6df7eb7","name":"meta/llama-2-70b-chat:fp8","project_id":"","tags":["chat"],"description":"70B-param
      model by Meta, a powerhouse for creative text generation and complex reasoning.","is_public":true,"created_at":"2024-03-15T10:00:00Z","updated_at":"2024-05-28T08:45:34.708427Z","has_eula":true,"provider":"meta","compatible_node_types":["H100"],"quantization_level":"fp8","region":"fr-par"},{"id":"3077ebd3-3a5a-47fc-91c2-da8cf6779c56","name":"wizardlm/wizardlm-70b-v1.0:fp16","project_id":"","tags":["instruct"],"description":"General
      use 70B-param model based on Llama 2.","is_public":true,"created_at":"2024-03-15T12:00:00Z","updated_at":"2024-05-28T08:45:34.765105Z","has_eula":true,"provider":"wizardlm","compatible_node_types":["H100-2"],"quantization_level":"fp16","region":"fr-par"},{"id":"729c0386-ddde-4209-ba91-fad5ec47e2bb","name":"wizardlm/wizardlm-70b-v1.0:fp8","project_id":"","tags":["instruct"],"description":"Empowering
      Large Pre-Trained Language Models to Follow Complex Instructions","is_public":true,"created_at":"2024-03-15T12:00:00Z","updated_at":null,"has_eula":true,"provider":"wizardlm","compatible_node_types":["H100"],"quantization_level":"fp8","region":"fr-par"},{"id":"d507757c-9bd8-47d5-87d5-bc8925d8d313","name":"meta/llama-2-7b-chat:fp8","project_id":"","tags":["chat"],"description":"Efficient
      7B-param model by Meta, fine-tuned for swift and dynamic chat engagement.","is_public":true,"created_at":"2024-04-16T09:58:13.738943Z","updated_at":"2024-05-28T08:45:34.673546Z","has_eula":true,"provider":"meta","compatible_node_types":["L4","H100"],"quantization_level":"fp8","region":"fr-par"},{"id":"a3d49280-ab4e-4e8b-93a2-dcaa1e79f31f","name":"meta/llama-2-7b-chat:fp16","project_id":"","tags":["chat"],"description":"Efficient
      7B-param model by Meta, fine-tuned for swift and dynamic chat engagement.","is_public":true,"created_at":"2024-04-16T09:58:13.797677Z","updated_at":"2024-05-28T08:45:34.694130Z","has_eula":true,"provider":"meta","compatible_node_types":["L4","H100"],"quantization_level":"fp16","region":"fr-par"},{"id":"4d834112-ed88-4394-9035-6eea562ec5f5","name":"sentence-transformers/sentence-t5-xxl:fp32","project_id":"","tags":["embedding"],"description":"Model
      from pre-trained Text-to-Text sentence encode.","is_public":true,"created_at":"2024-05-28T08:45:33.705028Z","updated_at":"2024-05-28T08:45:34.791819Z","has_eula":false,"provider":"sentence-transformers","compatible_node_types":["L4"],"quantization_level":"fp32","region":"fr-par"}],"total_count":10}'
    form: {}
    headers:
      User-Agent:
      - scaleway-sdk-go/v1.0.0-beta.7+dev (go1.22.2; darwin; amd64) cli-e2e-test
    url: https://api.scaleway.com/llm-inference/v1beta1/regions/fr-par/models?order_by=created_at_asc&page=1
    method: GET
  response:
    body: '{"models":[{"id":"6c68b256-ef4a-48d2-a794-9b63b5c6ba5d","name":"meta/llama-3-8b-instruct:bf16","project_id":"","tags":["instruct","chat"],"description":"Efficient
      8B-param model by Meta, fine-tuned for instruction and automation.","is_public":true,"created_at":"2024-03-14T00:00:00Z","updated_at":"2024-05-28T08:45:34.779337Z","has_eula":true,"provider":"meta","compatible_node_types":["L4"],"quantization_level":"bf16","region":"fr-par"},{"id":"c55d11d3-f717-4ede-82ac-48a74b84cbf1","name":"mistral/mixtral-8x7b-instruct-v0.1:int8","project_id":"","tags":["instruct"],"description":"A
      high-quality Mixture of Experts (MoE) model with open weights by Mistral AI,
      licensed under Apache 2.0.","is_public":true,"created_at":"2024-03-15T00:00:00Z","updated_at":"2024-05-28T08:45:34.749698Z","has_eula":false,"provider":"mistral","compatible_node_types":["H100"],"quantization_level":"int8","region":"fr-par"},{"id":"a7db3243-9d6a-4149-9ffb-081e24886d00","name":"mistral/mixtral-8x7b-instruct-v0.1:fp16","project_id":"","tags":["instruct"],"description":"A
      high-quality Mixture of Experts (MoE) model with open weights by Mistral AI,
      licensed under Apache 2.0.","is_public":true,"created_at":"2024-03-15T00:00:00Z","updated_at":"2024-05-28T08:45:34.736199Z","has_eula":false,"provider":"mistral","compatible_node_types":["H100-2"],"quantization_level":"fp16","region":"fr-par"},{"id":"2cf5427e-1cfd-4e9b-94e9-509e6a6a38a8","name":"meta/llama-2-70b-chat:fp16","project_id":"","tags":["chat"],"description":"70B-param
      model by Meta, a powerhouse for creative text generation and complex reasoning.","is_public":true,"created_at":"2024-03-15T10:00:00Z","updated_at":"2024-05-28T08:45:34.723363Z","has_eula":true,"provider":"meta","compatible_node_types":["H100-2"],"quantization_level":"fp16","region":"fr-par"},{"id":"efbca7c6-9b76-49b2-8789-f89cc6df7eb7","name":"meta/llama-2-70b-chat:fp8","project_id":"","tags":["chat"],"description":"70B-param
      model by Meta, a powerhouse for creative text generation and complex reasoning.","is_public":true,"created_at":"2024-03-15T10:00:00Z","updated_at":"2024-05-28T08:45:34.708427Z","has_eula":true,"provider":"meta","compatible_node_types":["H100"],"quantization_level":"fp8","region":"fr-par"},{"id":"3077ebd3-3a5a-47fc-91c2-da8cf6779c56","name":"wizardlm/wizardlm-70b-v1.0:fp16","project_id":"","tags":["instruct"],"description":"General
      use 70B-param model based on Llama 2.","is_public":true,"created_at":"2024-03-15T12:00:00Z","updated_at":"2024-05-28T08:45:34.765105Z","has_eula":true,"provider":"wizardlm","compatible_node_types":["H100-2"],"quantization_level":"fp16","region":"fr-par"},{"id":"729c0386-ddde-4209-ba91-fad5ec47e2bb","name":"wizardlm/wizardlm-70b-v1.0:fp8","project_id":"","tags":["instruct"],"description":"Empowering
      Large Pre-Trained Language Models to Follow Complex Instructions","is_public":true,"created_at":"2024-03-15T12:00:00Z","updated_at":null,"has_eula":true,"provider":"wizardlm","compatible_node_types":["H100"],"quantization_level":"fp8","region":"fr-par"},{"id":"d507757c-9bd8-47d5-87d5-bc8925d8d313","name":"meta/llama-2-7b-chat:fp8","project_id":"","tags":["chat"],"description":"Efficient
      7B-param model by Meta, fine-tuned for swift and dynamic chat engagement.","is_public":true,"created_at":"2024-04-16T09:58:13.738943Z","updated_at":"2024-05-28T08:45:34.673546Z","has_eula":true,"provider":"meta","compatible_node_types":["L4","H100"],"quantization_level":"fp8","region":"fr-par"},{"id":"a3d49280-ab4e-4e8b-93a2-dcaa1e79f31f","name":"meta/llama-2-7b-chat:fp16","project_id":"","tags":["chat"],"description":"Efficient
      7B-param model by Meta, fine-tuned for swift and dynamic chat engagement.","is_public":true,"created_at":"2024-04-16T09:58:13.797677Z","updated_at":"2024-05-28T08:45:34.694130Z","has_eula":true,"provider":"meta","compatible_node_types":["L4","H100"],"quantization_level":"fp16","region":"fr-par"},{"id":"4d834112-ed88-4394-9035-6eea562ec5f5","name":"sentence-transformers/sentence-t5-xxl:fp32","project_id":"","tags":["embedding"],"description":"Model
      from pre-trained Text-to-Text sentence encode.","is_public":true,"created_at":"2024-05-28T08:45:33.705028Z","updated_at":"2024-05-28T08:45:34.791819Z","has_eula":false,"provider":"sentence-transformers","compatible_node_types":["L4"],"quantization_level":"fp32","region":"fr-par"}],"total_count":10}'
    headers:
      Content-Security-Policy:
      - default-src 'none'; frame-ancestors 'none'
      Content-Type:
      - application/json
      Date:
      - Tue, 28 May 2024 13:22:47 GMT
      Server:
      - Scaleway API Gateway (fr-par-1;edge01)
      Strict-Transport-Security:
      - max-age=63072000
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - DENY
      X-Request-Id:
      - acc68dbe-2789-49a4-ab33-eea6368741d6
    status: 200 OK
    code: 200
    duration: ""
